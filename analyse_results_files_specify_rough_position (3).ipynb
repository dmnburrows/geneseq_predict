{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df045b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/examples/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57855f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 10:31:50.067184: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-29 10:31:50.067272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-29 10:31:51.129289: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-29 10:31:51.727163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-29 10:32:49.273117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-04-29 10:34:00.624539: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-04-29 10:34:00.624637: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: ga124\n",
      "2025-04-29 10:34:00.624644: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: ga124\n",
      "2025-04-29 10:34:00.624989: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 560.28.3\n",
      "2025-04-29 10:34:00.625028: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  560.28.03  Release Build  (dvs-builder@U16-A24-27-4)  Thu Jul 18 20:46:24 UTC 2024\n",
      "GCC version:  gcc version 8.5.0 20210514 (Red Hat 8.5.0-15) (GCC) \n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import pyfaidx\n",
    "import tensorflow as tf\n",
    "\n",
    "from baskerville import seqnn\n",
    "from baskerville import gene as bgene\n",
    "from baskerville import dna\n",
    "\n",
    "from borzoi_helpers import *\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213efae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model configuration\n",
    "\n",
    "params_file = 'params_pred.json'\n",
    "targets_file = 'targets_gtex.txt' #Subset of targets_human.txt\n",
    "\n",
    "seq_len = 524288\n",
    "n_folds = 1       #To use only one model fold, set to 'n_folds = 1'. To use all four folds, set 'n_folds = 4'.\n",
    "rc = True         #Average across reverse-complement prediction\n",
    "\n",
    "#Read model parameters\n",
    "\n",
    "with open(params_file) as params_open :\n",
    "    \n",
    "    params = json.load(params_open)\n",
    "    \n",
    "    params_model = params['model']\n",
    "    params_train = params['train']\n",
    "\n",
    "#Read targets\n",
    "\n",
    "targets_df = pd.read_csv(targets_file, index_col=0, sep='\\t')\n",
    "target_index = targets_df.index\n",
    "\n",
    "#Create local index of strand_pair (relative to sliced targets)\n",
    "if rc :\n",
    "    strand_pair = targets_df.strand_pair\n",
    "    \n",
    "    target_slice_dict = {ix : i for i, ix in enumerate(target_index.values.tolist())}\n",
    "    slice_pair = np.array([\n",
    "        target_slice_dict[ix] if ix in target_slice_dict else ix for ix in strand_pair.values.tolist()\n",
    "    ], dtype='int32')\n",
    "\n",
    "#Initialize model ensemble\n",
    "\n",
    "models = []\n",
    "for fold_ix in range(n_folds) :\n",
    "    \n",
    "    model_file = \"saved_models/f\" + str(fold_ix) + \"/model0_best.h5\"\n",
    "\n",
    "    seqnn_model = seqnn.SeqNN(params_model)\n",
    "    seqnn_model.restore(model_file, 0)\n",
    "    seqnn_model.build_slice(target_index)\n",
    "    if rc :\n",
    "        seqnn_model.strand_pair.append(slice_pair)\n",
    "    seqnn_model.build_ensemble(rc, [0])\n",
    "    \n",
    "    models.append(seqnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f832404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(splice_df) = 404837\n"
     ]
    }
   ],
   "source": [
    "#Initialize fasta sequence extractor\n",
    "\n",
    "fasta_open = pysam.Fastafile('hg38.fa')\n",
    "\n",
    "#Load splice site annotation\n",
    "\n",
    "splice_df = pd.read_csv('gencode41_basic_protein_splice.csv.gz', sep='\\t', compression='gzip')\n",
    "\n",
    "print(\"len(splice_df) = \" + str(len(splice_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4f79c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load GTF (optional; needed to compute exon coverage attributions for example gene)\n",
    "\n",
    "transcriptome = bgene.Transcriptome('gencode41_basic_nort.gtf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f852e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165797856\n",
      "['ENSG00000144285.23']\n",
      "165798368\n",
      "523264\n"
     ]
    }
   ],
   "source": [
    "search_gene = 'ENSG00000144285.23'\n",
    "center_pos = 166_060_000\n",
    "chrom = 'chr2'\n",
    "\n",
    "\n",
    "start = center_pos - seq_len // 2\n",
    "end = center_pos + seq_len // 2\n",
    "\n",
    "print(start)\n",
    "\n",
    "#Get exon bin range\n",
    "gene_keys = [gene_key for gene_key in transcriptome.genes.keys() if search_gene in gene_key]\n",
    "\n",
    "print(gene_keys)\n",
    "\n",
    "gene = transcriptome.genes[gene_keys[0]]\n",
    "\n",
    "#Determine output sequence start\n",
    "seq_out_start = start + seqnn_model.model_strides[0]*seqnn_model.target_crops[0]\n",
    "seq_out_len = seqnn_model.model_strides[0]*seqnn_model.target_lengths[0]\n",
    "\n",
    "print(seq_out_start)\n",
    "print(seq_out_len)\n",
    "\n",
    "#Determine output positions of gene exons\n",
    "gene_slice = gene.output_slice(seq_out_start, seq_out_len, seqnn_model.model_strides[0], False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed22269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood tracks = [9, 10, 11]\n",
      "muscle tracks = [47, 48, 49]\n",
      "brain tracks = [17, 18, 19]\n",
      "['RNA:adipose_tissue', 'RNA:adipose_tissue', 'RNA:adipose_tissue', 'RNA:adrenal_gland', 'RNA:adrenal_gland', 'RNA:adrenal_gland', 'RNA:bladder', 'RNA:bladder', 'RNA:bladder', 'RNA:blood', 'RNA:blood', 'RNA:blood', 'RNA:blood_vessel', 'RNA:blood_vessel', 'RNA:blood_vessel', 'RNA:bone_marrow', 'RNA:bone_marrow', 'RNA:brain', 'RNA:brain', 'RNA:brain', 'RNA:breast', 'RNA:breast', 'RNA:breast', 'RNA:cervix_uteri', 'RNA:cervix_uteri', 'RNA:cervix_uteri', 'RNA:colon', 'RNA:colon', 'RNA:colon', 'RNA:esophagus', 'RNA:esophagus', 'RNA:esophagus', 'RNA:fallopian_tube', 'RNA:fallopian_tube', 'RNA:fallopian_tube', 'RNA:heart', 'RNA:heart', 'RNA:heart', 'RNA:kidney', 'RNA:kidney', 'RNA:kidney', 'RNA:liver', 'RNA:liver', 'RNA:liver', 'RNA:lung', 'RNA:lung', 'RNA:lung', 'RNA:muscle', 'RNA:muscle', 'RNA:muscle', 'RNA:nerve', 'RNA:nerve', 'RNA:ovary', 'RNA:ovary', 'RNA:ovary', 'RNA:pancreas', 'RNA:pancreas', 'RNA:pancreas', 'RNA:pituitary', 'RNA:pituitary', 'RNA:pituitary', 'RNA:prostate', 'RNA:prostate', 'RNA:prostate', 'RNA:salivary_gland', 'RNA:salivary_gland', 'RNA:salivary_gland', 'RNA:skin', 'RNA:skin', 'RNA:skin', 'RNA:small_intestine', 'RNA:small_intestine', 'RNA:small_intestine', 'RNA:spleen', 'RNA:spleen', 'RNA:spleen', 'RNA:stomach', 'RNA:stomach', 'RNA:stomach', 'RNA:testis', 'RNA:testis', 'RNA:thyroid', 'RNA:thyroid', 'RNA:thyroid', 'RNA:uterus', 'RNA:uterus', 'RNA:vagina', 'RNA:vagina', 'RNA:vagina']\n"
     ]
    }
   ],
   "source": [
    "#Print index of GTEx blood and muscle tracks in targets file\n",
    "\n",
    "targets_df['local_index'] = np.arange(len(targets_df))\n",
    "\n",
    "print(\"blood tracks = \" + str(targets_df.loc[targets_df['description'] == 'RNA:blood']['local_index'].tolist()))\n",
    "print(\"muscle tracks = \" + str(targets_df.loc[targets_df['description'] == 'RNA:muscle']['local_index'].tolist()))\n",
    "print(\"brain tracks = \" + str(targets_df.loc[targets_df['description'] == 'RNA:brain']['local_index'].tolist()))\n",
    "\n",
    "print(list(targets_df['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf9537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the descriptions to a CSV file\n",
    "targets_df['description'].to_csv(\"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/track_descriptions.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7223638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_mut(sequence_one_hot_wt, poses, alts, start):\n",
    "    sequence_one_hot_mut = np.copy(sequence_one_hot_wt)\n",
    "    \n",
    "    for pos, alt in zip(poses, alts):\n",
    "        alt_ix = -1\n",
    "        if alt == 'A' :\n",
    "            alt_ix = 0\n",
    "        elif alt == 'C' :\n",
    "            alt_ix = 1\n",
    "        elif alt == 'G' :\n",
    "            alt_ix = 2\n",
    "        elif alt == 'T' :\n",
    "            alt_ix = 3\n",
    "\n",
    "        sequence_one_hot_mut[pos-start-1] = 0.\n",
    "        sequence_one_hot_mut[pos-start-1, alt_ix] = 1.\n",
    "                                   \n",
    "    return sequence_one_hot_mut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87d0c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           mutations       score\n",
      "0  166127880C;166127876T;166127868G;166127885G;16...  2338.07963\n",
      "1                                                       -1.00000\n"
     ]
    }
   ],
   "source": [
    "# We need a file that stores everything. Or we can make new files each time that save additional lines \n",
    "# each time, but never overwrite the previous. That sounds safer.\n",
    "import glob\n",
    "\n",
    "results_directory = \"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/results_files/\"\n",
    "all_results_files = glob.glob(results_directory + \"*results.csv\")\n",
    "\n",
    "#print(all_results_files)\n",
    "\n",
    "dfs = []\n",
    "for file in all_results_files:\n",
    "    df = pd.read_csv(file)  # Read each CSV file\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "# Keep only rows where the score is unique (appears only once)\n",
    "merged_df = merged_df[~merged_df['score'].duplicated(keep=False)]\n",
    "\n",
    "\n",
    "# FILTER FOR CERTAIN REGION\n",
    "\n",
    "region_to_filter_for = 166127870\n",
    "region_size = 500\n",
    "\n",
    "#print(merged_df.iloc[:, 0])\n",
    "\n",
    "def is_close_to_target(val):\n",
    "    try:\n",
    "        first_mut = str(val).split(';')[0][:-1]  # \"166127880C\" â†’ \"166127880\"\n",
    "        num = int(first_mut)\n",
    "#         print(num)\n",
    "        return abs(num - region_to_filter_for) < region_size\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "merged_df = merged_df[merged_df['mutations'].apply(is_close_to_target)]\n",
    "\n",
    "# The dataframe has a two columns - mutations and score\n",
    "\n",
    "# The mutations column is itself a semi-colon separated list of all mutations for this sequence. \n",
    "# eg 1824T;81324714G;234234C\n",
    "\n",
    "# Specify the number of top scores you want to keep\n",
    "N = 1  # For example, top 10 scores\n",
    "\n",
    "# Sort and select the top N rows based on the 'score' column\n",
    "top_n_df = merged_df.nlargest(N, 'score')\n",
    "\n",
    "top_n_df = pd.concat([top_n_df, pd.DataFrame([{'mutations': \"\", 'score': -1}])], ignore_index=True)\n",
    "\n",
    "# Show the filtered DataFrame\n",
    "print(top_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e895c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  mutations       score\n",
      "6824  166127502C;166127500G  1428.63907\n"
     ]
    }
   ],
   "source": [
    "top_n_df = merged_df.nsmallest(N, 'score')\n",
    "print(top_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0eb0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for mutations, score in zip(top_n_df[\"mutations\"], top_n_df[\"score\"]): \n",
    "    \n",
    "#     if mutations != \"\":\n",
    "#         continue\n",
    "    \n",
    "    this_attempts_results = {}\n",
    "    \n",
    "    # 1. read in mutations\n",
    "    if mutations != \"\":\n",
    "        mutations_d = {int(a[:-1]): a[-1]  for a in mutations.split(\";\")}\n",
    "    else:\n",
    "        mutations_d = {}\n",
    "    \n",
    "    # 2. add the mutations and one hot encode\n",
    "    sequence_one_hot = process_sequence(fasta_open, chrom, start, end)  # this is the WT sequence\n",
    "    \n",
    "    for pos, nt in mutations_d.items():\n",
    "        sequence_one_hot = one_hot_mut(sequence_one_hot, [pos], [nt], start)\n",
    "        \n",
    "        # Map index to base: A=0, C=1, G=2, T=3\n",
    "        bases = np.array(['A', 'C', 'G', 'T'])\n",
    "\n",
    "        # Find index of 1 in each row and map to base\n",
    "        sequence = ''.join(bases[np.argmax(sequence_one_hot, axis=1)])\n",
    "        import gzip\n",
    "        with gzip.open(\"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/results_files/\" + mutations + \"_decoded_sequence.txt.gz\", \"wb\") as f:\n",
    "            f.write(sequence.encode())\n",
    "        \n",
    "    # Predict\n",
    "    y = predict_tracks(models, sequence_one_hot)\n",
    "    \n",
    "    # Save to a dataframe for visualisation and analysis in R\n",
    "    y_np = y.squeeze()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(y_np)\n",
    "\n",
    "    # Save as a compressed CSV that R can read easily\n",
    "    df.to_csv(\"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/results_files/output_dataframes/\" + mutations + \"_output.csv.gz\", index=False, compression=\"gzip\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d164fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y.shape\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(y_np)\n",
    "\n",
    "# Save as a compressed CSV that R can read easily\n",
    "df.to_csv(\"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/results_files/result_df_wt.csv.gz\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b762872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map index to base: A=0, C=1, G=2, T=3\n",
    "bases = np.array(['A', 'C', 'G', 'T'])\n",
    "\n",
    "# Find index of 1 in each row and map to base\n",
    "sequence = ''.join(bases[np.argmax(sequence_one_hot, axis=1)])\n",
    "import gzip\n",
    "with gzip.open(\"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/results_files/decoded_sequence.txt.gz\", \"wb\") as f:\n",
    "    f.write(sequence.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a09a6fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166127880C;166127876T;166127868G;166127885G;166127883C;166127887C;166127884T\n"
     ]
    }
   ],
   "source": [
    "print(top_n_df['mutations'].iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
