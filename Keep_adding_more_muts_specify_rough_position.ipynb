{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbf2734",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'borzoi_helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbaskerville\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gene \u001b[38;5;28;01mas\u001b[39;00m bgene\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbaskerville\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dna\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mborzoi_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     21\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mset_verbosity(tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mERROR)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'borzoi_helpers'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import pyfaidx\n",
    "import tensorflow as tf\n",
    "\n",
    "from baskerville import seqnn\n",
    "from baskerville import gene as bgene\n",
    "from baskerville import dna\n",
    "\n",
    "from borzoi_helpers import *\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccb09329-46fa-4b4f-a997-2d3ed5b7f6f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'borzoi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mborzoi\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'borzoi'"
     ]
    }
   ],
   "source": [
    "import borzoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd57429a-9741-47ad-b25f-e72786f3323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: borzoi\n",
      "Version: 1.0.1.dev7+g5c93582\n",
      "Summary: borzoi\n",
      "Home-page: https://github.com/calico/borzoi\n",
      "Author: \n",
      "Author-email: David Kelley <drk@calicolabs.com>, Johannes Linder <jlinder@calicolabs.com>\n",
      "License: \n",
      "Location: /Users/k2585057/anaconda3/envs/borzoi/lib/python3.10/site-packages\n",
      "Editable project location: /Users/k2585057/baskerville/borzoi\n",
      "Requires: google-cloud-storage, h5py, intervaltree, joblib, matplotlib, natsort, networkx, numpy, pandas, pybedtools, pybigwig, pyfaidx, pyranges, pysam, qnorm, scikit-learn, scipy, seaborn, tensorflow, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show borzoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0af156-41cf-4c72-a827-cf79ccfc31e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: baskerville\n",
      "Version: 0.1.dev284+g63c245f\n",
      "Summary: baskerville\n",
      "Home-page: https://github.com/calico/baskerville\n",
      "Author: \n",
      "Author-email: \"Calico f(DNA)\" <drk@calicolabs.com>\n",
      "License: \n",
      "Location: /Users/k2585057/anaconda3/envs/borzoi/lib/python3.10/site-packages\n",
      "Editable project location: /Users/k2585057/baskerville\n",
      "Requires: google-cloud-storage, h5py, intervaltree, joblib, matplotlib, natsort, networkx, numpy, pandas, pybedtools, pybigwig, pyfaidx, pysam, qnorm, scikit-learn, scipy, seaborn, statsmodels, tabulate, tensorflow, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show baskerville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a3837-377e-4e3b-9164-3fca0517d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/examples/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6315e46-79ce-4653-ba71-242e74516b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# #Download model weights\n",
    "# for fold in f0 f1 f2 f3; do\n",
    "#   mkdir -p \"saved_models/$fold/\"\n",
    "#   local_model=\"saved_models/$fold/model0_best.h5\"\n",
    "#   if [ -f \"$local_model\" ]; then\n",
    "#     echo \"$fold model already exists.\"\n",
    "#   else\n",
    "#     wget --progress=bar:force \"https://storage.googleapis.com/seqnn-share/borzoi/$fold/model0_best.h5\" -O \"$local_model\"\n",
    "#   fi\n",
    "# done\n",
    "\n",
    "# #Download and uncompress annotation files\n",
    "# if [ -f gencode41_basic_nort.gtf ]; then\n",
    "#   echo \"Annotation already exists.\"\n",
    "# else\n",
    "#   wget -O - https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_nort.gtf.gz | gunzip -c > gencode41_basic_nort.gtf\n",
    "# fi\n",
    "# if [ -f gencode41_basic_protein_splice.csv.gz ]; then\n",
    "#   echo \"Splice sites already exist.\"\n",
    "# else\n",
    "#   wget https://storage.googleapis.com/seqnn-share/helper/gencode41_basic_protein_splice.csv.gz\n",
    "# fi\n",
    "# if [ -f polyadb_human_v3.csv.gz ]; then\n",
    "#   echo \"PolyA sites already exist.\"\n",
    "# else\n",
    "#   wget https://storage.googleapis.com/seqnn-share/helper/polyadb_human_v3.csv.gz\n",
    "# fi\n",
    "\n",
    "# #Download and index hg38 genome\n",
    "# if [ -f hg38.fa ]; then\n",
    "#   echo \"Human genome FASTA already exists.\"\n",
    "# else\n",
    "#   wget -O - http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz | gunzip -c > hg38.fa\n",
    "# fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3dfe8ad-5c40-44b1-aab6-58491694da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyfaidx.Faidx('hg38.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5fbf3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 18:52:15.595494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 70557 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "#Model configuration\n",
    "\n",
    "params_file = 'params_pred.json'\n",
    "targets_file = 'targets_gtex.txt' #Subset of targets_human.txt\n",
    "\n",
    "seq_len = 524288\n",
    "n_folds = 1       #To use only one model fold, set to 'n_folds = 1'. To use all four folds, set 'n_folds = 4'.\n",
    "rc = True         #Average across reverse-complement prediction\n",
    "\n",
    "#Read model parameters\n",
    "\n",
    "with open(params_file) as params_open :\n",
    "    \n",
    "    params = json.load(params_open)\n",
    "    \n",
    "    params_model = params['model']\n",
    "    params_train = params['train']\n",
    "\n",
    "#Read targets\n",
    "\n",
    "targets_df = pd.read_csv(targets_file, index_col=0, sep='\\t')\n",
    "target_index = targets_df.index\n",
    "\n",
    "#Create local index of strand_pair (relative to sliced targets)\n",
    "if rc :\n",
    "    strand_pair = targets_df.strand_pair\n",
    "    \n",
    "    target_slice_dict = {ix : i for i, ix in enumerate(target_index.values.tolist())}\n",
    "    slice_pair = np.array([\n",
    "        target_slice_dict[ix] if ix in target_slice_dict else ix for ix in strand_pair.values.tolist()\n",
    "    ], dtype='int32')\n",
    "\n",
    "#Initialize model ensemble\n",
    "\n",
    "models = []\n",
    "for fold_ix in range(n_folds) :\n",
    "    \n",
    "    model_file = \"saved_models/f\" + str(fold_ix) + \"/model0_best.h5\"\n",
    "\n",
    "    seqnn_model = seqnn.SeqNN(params_model)\n",
    "    seqnn_model.restore(model_file, 0)\n",
    "    seqnn_model.build_slice(target_index)\n",
    "    if rc :\n",
    "        seqnn_model.strand_pair.append(slice_pair)\n",
    "    seqnn_model.build_ensemble(rc, [0])\n",
    "    \n",
    "    models.append(seqnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f010781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(splice_df) = 404837\n"
     ]
    }
   ],
   "source": [
    "#Initialize fasta sequence extractor\n",
    "\n",
    "fasta_open = pysam.Fastafile('hg38.fa')\n",
    "\n",
    "#Load splice site annotation\n",
    "\n",
    "splice_df = pd.read_csv('gencode41_basic_protein_splice.csv.gz', sep='\\t', compression='gzip')\n",
    "\n",
    "print(\"len(splice_df) = \" + str(len(splice_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "467efc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load GTF (optional; needed to compute exon coverage attributions for example gene)\n",
    "\n",
    "transcriptome = bgene.Transcriptome('gencode41_basic_nort.gtf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12df90e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165797856\n",
      "['ENSG00000144285.23']\n",
      "165798368\n",
      "523264\n"
     ]
    }
   ],
   "source": [
    "search_gene = 'ENSG00000144285.23'\n",
    "center_pos = 166_060_000\n",
    "chrom = 'chr2'\n",
    "\n",
    "\n",
    "start = center_pos - seq_len // 2\n",
    "end = center_pos + seq_len // 2\n",
    "\n",
    "print(start)\n",
    "\n",
    "#Get exon bin range\n",
    "gene_keys = [gene_key for gene_key in transcriptome.genes.keys() if search_gene in gene_key]\n",
    "\n",
    "print(gene_keys)\n",
    "\n",
    "gene = transcriptome.genes[gene_keys[0]]\n",
    "\n",
    "#Determine output sequence start\n",
    "seq_out_start = start + seqnn_model.model_strides[0]*seqnn_model.target_crops[0]\n",
    "seq_out_len = seqnn_model.model_strides[0]*seqnn_model.target_lengths[0]\n",
    "\n",
    "print(seq_out_start)\n",
    "print(seq_out_len)\n",
    "#Determine output positions of gene exons\n",
    "gene_slice = gene.output_slice(seq_out_start, seq_out_len, seqnn_model.model_strides[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073e4711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood tracks = [9, 10, 11]\n",
      "muscle tracks = [47, 48, 49]\n",
      "brain tracks = [17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "#Print index of GTEx blood and muscle tracks in targets file\n",
    "\n",
    "targets_df['local_index'] = np.arange(len(targets_df))\n",
    "print(\"blood tracks = \" + str(targets_df.loc[targets_df['description'] == 'RNA:blood']['local_index'].tolist()))\n",
    "print(\"muscle tracks = \" + str(targets_df.loc[targets_df['description'] == 'RNA:muscle']['local_index'].tolist()))\n",
    "print(\"brain tracks = \" + str(targets_df.loc[targets_df['description'] == 'RNA:brain']['local_index'].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231c3c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RNA:adipose_tissue', 'RNA:adipose_tissue', 'RNA:adipose_tissue', 'RNA:adrenal_gland', 'RNA:adrenal_gland', 'RNA:adrenal_gland', 'RNA:bladder', 'RNA:bladder', 'RNA:bladder', 'RNA:blood', 'RNA:blood', 'RNA:blood', 'RNA:blood_vessel', 'RNA:blood_vessel', 'RNA:blood_vessel', 'RNA:bone_marrow', 'RNA:bone_marrow', 'RNA:brain', 'RNA:brain', 'RNA:brain', 'RNA:breast', 'RNA:breast', 'RNA:breast', 'RNA:cervix_uteri', 'RNA:cervix_uteri', 'RNA:cervix_uteri', 'RNA:colon', 'RNA:colon', 'RNA:colon', 'RNA:esophagus', 'RNA:esophagus', 'RNA:esophagus', 'RNA:fallopian_tube', 'RNA:fallopian_tube', 'RNA:fallopian_tube', 'RNA:heart', 'RNA:heart', 'RNA:heart', 'RNA:kidney', 'RNA:kidney', 'RNA:kidney', 'RNA:liver', 'RNA:liver', 'RNA:liver', 'RNA:lung', 'RNA:lung', 'RNA:lung', 'RNA:muscle', 'RNA:muscle', 'RNA:muscle', 'RNA:nerve', 'RNA:nerve', 'RNA:ovary', 'RNA:ovary', 'RNA:ovary', 'RNA:pancreas', 'RNA:pancreas', 'RNA:pancreas', 'RNA:pituitary', 'RNA:pituitary', 'RNA:pituitary', 'RNA:prostate', 'RNA:prostate', 'RNA:prostate', 'RNA:salivary_gland', 'RNA:salivary_gland', 'RNA:salivary_gland', 'RNA:skin', 'RNA:skin', 'RNA:skin', 'RNA:small_intestine', 'RNA:small_intestine', 'RNA:small_intestine', 'RNA:spleen', 'RNA:spleen', 'RNA:spleen', 'RNA:stomach', 'RNA:stomach', 'RNA:stomach', 'RNA:testis', 'RNA:testis', 'RNA:thyroid', 'RNA:thyroid', 'RNA:thyroid', 'RNA:uterus', 'RNA:uterus', 'RNA:vagina', 'RNA:vagina', 'RNA:vagina']\n"
     ]
    }
   ],
   "source": [
    "print(list(targets_df['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83400a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_mut(sequence_one_hot_wt, poses, alts, start):\n",
    "    sequence_one_hot_mut = np.copy(sequence_one_hot_wt)\n",
    "    \n",
    "    for pos, alt in zip(poses, alts):\n",
    "        alt_ix = -1\n",
    "        if alt == 'A' :\n",
    "            alt_ix = 0\n",
    "        elif alt == 'C' :\n",
    "            alt_ix = 1\n",
    "        elif alt == 'G' :\n",
    "            alt_ix = 2\n",
    "        elif alt == 'T' :\n",
    "            alt_ix = 3\n",
    "\n",
    "        sequence_one_hot_mut[pos-start-1] = 0.\n",
    "        sequence_one_hot_mut[pos-start-1, alt_ix] = 1.\n",
    "                                   \n",
    "    return sequence_one_hot_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9873a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a file that stores everything. Or we can make new files each time that save additional lines \n",
    "# each time, but never overwrite the previous. That sounds safer.\n",
    "import glob\n",
    "\n",
    "results_directory = \"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/results_files/\"\n",
    "all_results_files = glob.glob(results_directory + \"*results.csv\")\n",
    "\n",
    "print(all_results_files)\n",
    "\n",
    "dfs = []\n",
    "for file in all_results_files:\n",
    "    df = pd.read_csv(file)  # Read each CSV file\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "# Keep only rows where the score is unique (appears only once)\n",
    "merged_df = merged_df[~merged_df['score'].duplicated(keep=False)]\n",
    "\n",
    "\n",
    "# FILTER FOR CERTAIN REGION\n",
    "region_to_filter_for = 166127454\n",
    "region_size = 50\n",
    "\n",
    "#print(merged_df.iloc[:, 0])\n",
    "\n",
    "def is_close_to_target(val):\n",
    "    try:\n",
    "        first_mut = str(val).split(';')[0][:-1]  # \"166127880C\" → \"166127880\"\n",
    "        num = int(first_mut)\n",
    "    #print(num)\n",
    "        return abs(num - region_to_filter_for) < region_size\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "merged_df = merged_df[merged_df['mutations'].apply(is_close_to_target)]\n",
    "\n",
    "# The dataframe has a two columns - mutations and score\n",
    "\n",
    "# The mutations column is itself a semi-colon separated list of all mutations for this sequence. \n",
    "# eg 1824T;81324714G;234234C\n",
    "\n",
    "# Specify the number of top scores you want to keep\n",
    "N = 10  # For example, top 10 scores\n",
    "\n",
    "# Sort and select the top N rows based on the 'score' column\n",
    "top_n_df = merged_df.nlargest(N, 'score')\n",
    "\n",
    "# Show the filtered DataFrame\n",
    "print(top_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc713993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{166127381: 'T', 166127387: 'G', 166127367: 'G'}\n",
      "1722.21584\n",
      "1744.52665\n",
      "1770.7834\n",
      "1800.74501\n",
      "1805.83859\n",
      "1844.6345\n",
      "{166127381: 'T', 166127387: 'G', 166127367: 'C'}\n",
      "{166127381: 'T', 166127387: 'G', 166127367: 'T'}\n",
      "{166127381: 'T', 166127387: 'G'}\n",
      "{166127381: 'T', 166127387: 'G', 166127367: 'A'}\n",
      "{166127880: 'C', 166127876: 'T'}\n",
      "{166127876: 'T', 166127880: 'C'}\n",
      "{166127560: 'G', 166127564: 'C'}\n",
      "{166127502: 'C', 166127520: 'C'}\n",
      "{166127881: 'C', 166127876: 'T'}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_trim = 169000 // 32\n",
    "end_trim = (166175000 - start) // 32\n",
    "window_size = 20 # window in which to do second mutation\n",
    "\n",
    "best_score = -1\n",
    "\n",
    "# For each example do the following\n",
    "\n",
    "for mutations, score in zip(top_n_df[\"mutations\"], top_n_df[\"score\"]): \n",
    "    \n",
    "    this_attempts_results = {}\n",
    "    \n",
    "    # 1. read in mutations\n",
    "    mutations_d = {int(a[:-1]): a[-1]  for a in mutations.split(\";\")}\n",
    "    print(mutations_d)\n",
    "    \n",
    "    # 2. work out where can be mutated in this round of ISM\n",
    "    mutation_window_start = max(mutations_d.keys()) - window_size\n",
    "    mutation_window_end = min(mutations_d.keys()) + window_size\n",
    "    \n",
    "    # 3. add the previous mutations and one hot encode\n",
    "    sequence_one_hot = process_sequence(fasta_open, chrom, start, end)  # this is the WT sequence\n",
    "    \n",
    "    for pos, nt in mutations_d.items():\n",
    "        sequence_one_hot = one_hot_mut(sequence_one_hot, [pos], [nt], start)\n",
    "        \n",
    "    # 4. Now mutate all possible nucleotides and do the prediction\n",
    "    for pos in range(mutation_window_start, mutation_window_end):\n",
    "        for new_nt in ['A', 'C', 'T', 'G']:\n",
    "            new_one_hot = one_hot_mut(sequence_one_hot, [pos], [new_nt], start)\n",
    "            \n",
    "            y_mut = predict_tracks(models, new_one_hot)\n",
    "            brain_mut = 100000 * y_mut[:, :, start_trim:end_trim, 17:20] #17, 18, 19 are the brain tracks\n",
    "            mut_sum = int(tf.reduce_sum(brain_mut)) / 100000\n",
    "            \n",
    "            these_mutations = mutations + \";\" + str(pos) + new_nt\n",
    "            \n",
    "            this_attempts_results[these_mutations] = mut_sum\n",
    "            \n",
    "            if mut_sum > best_score:\n",
    "                print(mut_sum)\n",
    "                best_score = mut_sum\n",
    "            \n",
    "        \n",
    "    out_df = pd.DataFrame([{\"mutations\": k, \"score\": v} for k, v in this_attempts_results.items()])\n",
    "    \n",
    "    # Generate unique filename using current date and time\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"mut_scores_{timestamp}_results.csv\"\n",
    "\n",
    "    # Save to CSV\n",
    "    out_df.to_csv(results_directory + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               mutations       score\n",
      "2727   166127502C;166127520C;166127517G;166127506C;16...  1898.39676\n",
      "5513   166127502C;166127520C;166127517G;166127506C;16...  1898.07302\n",
      "19280  166127502C;166127520C;166127512G;166127506C;16...  1868.58376\n",
      "5512   166127502C;166127520C;166127517G;166127506C;16...  1866.68304\n",
      "2677   166127502C;166127520C;166127517G;166127506C;16...  1861.01037\n",
      "2730   166127502C;166127520C;166127517G;166127506C;16...  1859.62719\n",
      "2691   166127502C;166127520C;166127517G;166127506C;16...  1858.52937\n",
      "2743   166127502C;166127520C;166127517G;166127506C;16...  1854.38006\n",
      "10545  166127502C;166127520C;166127512G;166127506C;16...  1853.06066\n",
      "2713   166127502C;166127520C;166127517G;166127506C;16...  1851.91901\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'G'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 18:52:55.784950: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587.86075\n",
      "1898.39676\n",
      "1901.08898\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127503: 'G', 166127512: 'G'}\n",
      "1607.79008\n",
      "1898.07302\n",
      "1898.39676\n",
      "1910.60994\n",
      "{166127502: 'C', 166127520: 'C', 166127512: 'G', 166127506: 'C', 166127511: 'T', 166127503: 'G', 166127513: 'T'}\n",
      "1621.21877\n",
      "1868.58376\n",
      "1869.68161\n",
      "1910.60994\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127503: 'G', 166127512: 'T'}\n",
      "1640.96445\n",
      "1866.68304\n",
      "1898.07302\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'C', 166127500: 'C'}\n",
      "1617.47541\n",
      "1861.01037\n",
      "1898.39676\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'C', 166127513: 'T'}\n",
      "1637.05517\n",
      "1859.62719\n",
      "1889.77724\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'C', 166127503: 'G'}\n",
      "1622.59237\n",
      "1858.52937\n",
      "1861.01037\n",
      "1866.68304\n",
      "1898.07302\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'C', 166127516: 'G'}\n",
      "1614.99638\n",
      "1854.38006\n",
      "1856.9957\n",
      "1861.01037\n",
      "{166127502: 'C', 166127520: 'C', 166127512: 'G', 166127506: 'C', 166127511: 'T', 166127516: 'G'}\n",
      "1568.746\n",
      "1853.06066\n",
      "1863.87705\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'C', 166127509: 'C'}\n",
      "1558.47352\n",
      "1851.91901\n",
      "1853.41679\n",
      "1861.01037\n",
      "1901.08898\n",
      "                                               mutations       score\n",
      "12137  166127502C;166127520C;166127512G;166127506C;16...  1910.60994\n",
      "14793  166127502C;166127520C;166127517G;166127506C;16...  1901.08898\n",
      "3023   166127502C;166127520C;166127517G;166127506C;16...  1898.39676\n",
      "1063   166127502C;166127520C;166127517G;166127506C;16...  1898.07302\n",
      "12942  166127502C;166127520C;166127517G;166127506C;16...  1890.33431\n",
      "1066   166127502C;166127520C;166127517G;166127506C;16...  1889.77724\n",
      "17420  166127502C;166127520C;166127517G;166127506C;16...  1883.92597\n",
      "12927  166127502C;166127520C;166127517G;166127506C;16...  1878.47357\n",
      "12943  166127502C;166127520C;166127517G;166127506C;16...  1870.48816\n",
      "12124  166127502C;166127520C;166127512G;166127506C;16...  1869.68161\n",
      "{166127502: 'C', 166127520: 'C', 166127512: 'G', 166127506: 'C', 166127511: 'T', 166127503: 'G', 166127513: 'T', 166127517: 'G'}\n",
      "1632.35542\n",
      "1910.60994\n",
      "1913.39921\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'G', 166127509: 'C'}\n",
      "1534.74586\n",
      "1901.08898\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'G'}\n",
      "1587.86075\n",
      "1898.39676\n",
      "1901.08898\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'G', 166127503: 'G'}\n",
      "1607.79008\n",
      "1898.07302\n",
      "1898.39676\n",
      "1910.60994\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127503: 'G', 166127512: 'G', 166127513: 'A'}\n",
      "1614.18088\n",
      "1890.33431\n",
      "1910.60994\n",
      "{166127502: 'C', 166127520: 'C', 166127517: 'G', 166127506: 'C', 166127511: 'T', 166127512: 'C', 166127503: 'G', 166127513: 'T'}\n",
      "1649.18237\n",
      "1889.77724\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "# COMBINE TO ENDLESS WHILE LOOP\n",
    "start_trim = 169000 // 32\n",
    "end_trim = (166175000 - start) // 32\n",
    "window_size = 20 # window in which to do second mutation\n",
    "region_to_filter_for = 166127454\n",
    "region_size = 50\n",
    "\n",
    "def is_close_to_target(val):\n",
    "    try:\n",
    "        first_mut = str(val).split(';')[0][:-1]  # \"166127880C\" → \"166127880\"\n",
    "        num = int(first_mut)\n",
    "        return abs(num - region_to_filter_for) < region_size\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "while True:\n",
    "    results_directory = \"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/results_files/\"\n",
    "    all_results_files = glob.glob(results_directory + \"*results.csv\")\n",
    "\n",
    "    dfs = []\n",
    "    for file in all_results_files:\n",
    "        df = pd.read_csv(file)  # Read each CSV file\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    merged_df = merged_df.drop_duplicates(subset='score', keep='first')  # remove duplicates\n",
    "    \n",
    "    # FILTER FOR CERTAIN REGION\n",
    "\n",
    "    merged_df = merged_df[merged_df['mutations'].apply(is_close_to_target)]\n",
    "\n",
    "\n",
    "    # The dataframe has a two columns - mutations and score\n",
    "\n",
    "    # The mutations column is itself a semi-colon separated list of all mutations for this sequence. \n",
    "    # eg 1824T;81324714G;234234C\n",
    "\n",
    "    # Specify the number of top scores you want to keep\n",
    "    N = 10  # For example, top 10 scores\n",
    "\n",
    "    # Sort and select the top N rows based on the 'score' column\n",
    "    top_n_df = merged_df.nlargest(N, 'score')\n",
    "\n",
    "    # Show the filtered DataFrame\n",
    "    print(top_n_df)\n",
    "    \n",
    "    for mutations, score in zip(top_n_df[\"mutations\"], top_n_df[\"score\"]): \n",
    "        best_score = -1\n",
    "    \n",
    "        this_attempts_results = {}\n",
    "\n",
    "        # 1. read in mutations\n",
    "        mutations_d = {int(a[:-1]): a[-1]  for a in mutations.split(\";\")}\n",
    "        print(mutations_d)\n",
    "\n",
    "        # 2. work out where can be mutated in this round of ISM\n",
    "        mutation_window_start = max(mutations_d.keys()) - window_size\n",
    "        mutation_window_end = min(mutations_d.keys()) + window_size\n",
    "\n",
    "        # 3. add the previous mutations and one hot encode\n",
    "        sequence_one_hot = process_sequence(fasta_open, chrom, start, end)  # this is the WT sequence\n",
    "\n",
    "        for pos, nt in mutations_d.items():\n",
    "            sequence_one_hot = one_hot_mut(sequence_one_hot, [pos], [nt], start)\n",
    "\n",
    "        # 4. Now mutate all possible nucleotides and do the prediction\n",
    "        for pos in range(mutation_window_start, mutation_window_end):\n",
    "            for new_nt in ['A', 'C', 'T', 'G']:\n",
    "                new_one_hot = one_hot_mut(sequence_one_hot, [pos], [new_nt], start)\n",
    "\n",
    "                y_mut = predict_tracks(models, new_one_hot)\n",
    "                brain_mut = 100000 * y_mut[:, :, start_trim:end_trim, 17:20] #17, 18, 19 are the brain tracks\n",
    "                mut_sum = int(tf.reduce_sum(brain_mut)) / 100000\n",
    "\n",
    "                these_mutations = mutations + \";\" + str(pos) + new_nt\n",
    "\n",
    "                this_attempts_results[these_mutations] = mut_sum\n",
    "\n",
    "                if mut_sum > best_score:\n",
    "                    print(mut_sum)\n",
    "                    best_score = mut_sum\n",
    "\n",
    "        out_df = pd.DataFrame([{\"mutations\": k, \"score\": v} for k, v in this_attempts_results.items()])\n",
    "\n",
    "        # Generate unique filename using current date and time\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"mut_scores_{timestamp}_results.csv\"\n",
    "\n",
    "        # Save to CSV\n",
    "        out_df.to_csv(results_directory + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb452a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 19:00:02.521396: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-20\n",
      "-19\n",
      "-18\n",
      "-17\n",
      "-16\n",
      "-15\n",
      "-14\n",
      "-13\n",
      "-12\n",
      "-11\n",
      "-10\n",
      "-9\n",
      "-8\n",
      "-7\n",
      "-6\n",
      "-5\n",
      "-4\n",
      "-3\n",
      "-2\n",
      "-1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "best_single_muts = pd.read_csv(\"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/best_single_muts.csv\")\n",
    "\n",
    "best_single_muts = best_single_muts.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "start_trim = 169000 // 32\n",
    "end_trim = (166175000 - start) // 32\n",
    "window = 20 # window in which to do second mutation\n",
    "\n",
    "# Specify the output CSV file path\n",
    "csv_file = \"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/ism_results_second_mut.csv\"\n",
    "\n",
    "# Open the CSV file in append mode to add data\n",
    "# with open(csv_file, mode='w') as file:\n",
    "    \n",
    "    file.write('position,nucleotide,score,first_mutation\\n')\n",
    "\n",
    "    # First get unmutated sequence\n",
    "    sequence_one_hot_wt = process_sequence(fasta_open, chrom, start, end)\n",
    "    y_wt = predict_tracks(models, sequence_one_hot_wt)\n",
    "    brain_wt = 100000 * y_wt[:, :, start_trim:end_trim, 17:20]\n",
    "    wt_sum = int(tf.reduce_sum(brain_wt)) / 100000\n",
    "    \n",
    "    file.write('-,-,' + str(wt_sum) + ',-\\n')\n",
    "    \n",
    "yo = 0\n",
    "\n",
    "for p, mut in zip(best_single_muts['position'], best_single_muts['nucleotide']):\n",
    "    \n",
    "    sequence_one_hot_1mut = one_hot_mut(sequence_one_hot_wt, [p], [mut], start)\n",
    "    \n",
    "    for offset in range(-window, window):\n",
    "        if offset == 0:\n",
    "            continue\n",
    "            \n",
    "        print(offset)\n",
    "        \n",
    "        if p + offset - start < 0:\n",
    "            continue\n",
    "        \n",
    "        if p + offset - start > seq_len:\n",
    "            continue\n",
    "        \n",
    "        for new_nt in ['A', 'C', 'T', 'G']:\n",
    "            sequence_one_hot_2mut = one_hot_mut(sequence_one_hot_1mut, [p+offset], [new_nt], start)\n",
    "            \n",
    "            if tf.reduce_all(tf.equal(sequence_one_hot_1mut, sequence_one_hot_2mut)):\n",
    "                continue\n",
    "\n",
    "\n",
    "            y_mut = predict_tracks(models, sequence_one_hot_2mut)\n",
    "            brain_mut = 100000 * y_mut[:, :, start_trim:end_trim, 17:20]\n",
    "            mut_sum = int(tf.reduce_sum(brain_mut)) / 100000\n",
    "\n",
    "            with open(csv_file, 'a') as file:\n",
    "                file.write(str(p+offset) + ',' + new_nt + ',' + str(mut_sum) + ',' + str(p) + ';' + mut + '\\n')\n",
    "            \n",
    "        yo += 1\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da27a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Read the best_targets.csv file\n",
    "# best_targets = pd.read_csv(\"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/best_targets.csv\")\n",
    "\n",
    "# start_trim = 169000 // 32\n",
    "# end_trim = (166175000 - start) // 32\n",
    "\n",
    "# # Specify the output CSV file path\n",
    "# csv_file = \"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/ism_results.csv\"\n",
    "\n",
    "# # Open the CSV file in append mode to add data\n",
    "# with open(csv_file, mode='w') as file:\n",
    "    \n",
    "#     file.write('position,nucleotide,score\\n')\n",
    "\n",
    "#     # First get unmutated sequence\n",
    "#     sequence_one_hot_wt = process_sequence(fasta_open, chrom, start, end)\n",
    "#     y_wt = predict_tracks(models, sequence_one_hot_wt)\n",
    "#     brain_wt = 100000 * y_wt[:, :, start_trim:end_trim, 17:20]\n",
    "#     wt_sum = int(tf.reduce_sum(brain_wt)) / 100000\n",
    "    \n",
    "#     file.write('-,-,' + str(wt_sum) + '\\n')\n",
    "    \n",
    "\n",
    "# yo = 0\n",
    "\n",
    "\n",
    "# # Now go through all possible mutants\n",
    "# for p in best_targets['pos']:\n",
    "#     for new_nt in ['A', 'C', 'G', 'T']:\n",
    "#         sequence_one_hot_mut = one_hot_mut(sequence_one_hot_wt, [p], [new_nt], start)\n",
    "\n",
    "#         if tf.reduce_all(tf.equal(sequence_one_hot_wt, sequence_one_hot_mut)):\n",
    "#             continue\n",
    "\n",
    "#         y_mut = predict_tracks(models, sequence_one_hot_mut)\n",
    "#         brain_mut = 100000 * y_mut[:, :, start_trim:end_trim, 17:20]\n",
    "#         mut_sum = int(tf.reduce_sum(brain_mut)) / 100000\n",
    "        \n",
    "#         with open(csv_file, 'a') as file:\n",
    "#             file.write(str(p) + ',' + new_nt + ',' + str(mut_sum) + '\\n')\n",
    "            \n",
    "#         yo += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef67ac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     position nucleotide       score  downsampled\n",
      "0   165991702          A  1588.90755       165990\n",
      "1   165991705          C  1586.05150       165990\n",
      "2   165991706          A  1587.59867       165990\n",
      "3   165991706          T  1587.05882       165990\n",
      "4   166091182          A  1615.19521       166090\n",
      "5   166127381          T  1616.44106       166120\n",
      "6   166127454          C  1586.54045       166120\n",
      "7   166127456          A  1586.23943       166120\n",
      "8   166127493          G  1596.53002       166120\n",
      "9   166127502          C  1612.17347       166120\n",
      "10  166127560          G  1605.82294       166120\n",
      "11  166127876          T  1590.35662       166120\n",
      "12  166127878          C  1599.54436       166120\n",
      "13  166127880          C  1611.09994       166120\n",
      "14  166127881          C  1599.09431       166120\n",
      "15  166149042          C  1618.76229       166140\n",
      "16  166149048          T  1586.16778       166140\n"
     ]
    }
   ],
   "source": [
    "best_single_muts = pd.read_csv(\"/camp/home/wilkino/home/POSTDOC/borzoi/borzoi/jenna/best_single_muts.csv\")\n",
    "print(best_single_muts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in best_targets['pos']:\n",
    "    print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad40138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Predict for chr10_116952944_T_C\n",
    "# (~6 minutes on CPU w 1 fold; ~2 minutes on GPU)\n",
    "\n",
    "save_figs = False\n",
    "save_suffix = '_meh_'\n",
    "\n",
    "sequence_one_hot_wt = process_sequence(fasta_open, chrom, start, end)\n",
    "\n",
    "#Induce mutation(s)\n",
    "sequence_one_hot_mut = np.copy(sequence_one_hot_wt)\n",
    "\n",
    "for pos, alt in zip(poses, alts) :\n",
    "    alt_ix = -1\n",
    "    if alt == 'A' :\n",
    "        alt_ix = 0\n",
    "    elif alt == 'C' :\n",
    "        alt_ix = 1\n",
    "    elif alt == 'G' :\n",
    "        alt_ix = 2\n",
    "    elif alt == 'T' :\n",
    "        alt_ix = 3\n",
    "\n",
    "    sequence_one_hot_mut[pos-start-1] = 0.\n",
    "    sequence_one_hot_mut[pos-start-1, alt_ix] = 1.\n",
    "\n",
    "#Make predictions\n",
    "y_wt = predict_tracks(models, sequence_one_hot_wt)\n",
    "y_mut = predict_tracks(models, sequence_one_hot_mut)\n",
    "\n",
    "print('done')\n",
    "\n",
    "\n",
    "\n",
    "brain_wt = y_wt[:, :, :, 17:20]\n",
    "brain_mut = y_mut[:, :, :, 17:20]\n",
    "print(tf.reduce_sum(brain_wt))\n",
    "print(tf.reduce_sum(brain_mut))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize quantized tracks over SNP\n",
    "\n",
    "plot_window = 131072*2\n",
    "bin_size = 32\n",
    "pad = 16\n",
    "\n",
    "rescale_tracks = True\n",
    "normalize_counts = False\n",
    "\n",
    "anno_df = None #splice_df\n",
    "\n",
    "#Tracks\n",
    "track_indices = [\n",
    "    np.arange(0, 89).tolist(),\n",
    "    [9, 10, 11],\n",
    "    [47, 48, 49],\n",
    "    [17, 18, 19],\n",
    "]\n",
    "\n",
    "track_names = [\n",
    "    'GTEx Coverage (All tissues)',\n",
    "    'GTEx Coverage (Blood)',\n",
    "    'GTEx Coverage (Muscle)',\n",
    "    'Brain',\n",
    "]\n",
    "\n",
    "track_scales = [0.01]*4\n",
    "track_transforms = [3./4.]*4\n",
    "soft_clips = [384.]*4\n",
    "\n",
    "print(\"-- Counts --\")\n",
    "plot_coverage_track_pair_bins(\n",
    "    y_wt,\n",
    "    y_mut,\n",
    "    chrom,\n",
    "    start,\n",
    "    center_pos,\n",
    "    poses,\n",
    "    track_indices,\n",
    "    track_names,\n",
    "    track_scales,\n",
    "    track_transforms,\n",
    "    soft_clips,\n",
    "    plot_window=plot_window,\n",
    "    normalize_window=1 * plot_window,\n",
    "    bin_size=bin_size,\n",
    "    pad=pad,\n",
    "    rescale_tracks=rescale_tracks,\n",
    "    normalize_counts=normalize_counts,\n",
    "    save_figs=save_figs,\n",
    "    save_suffix=save_suffix,\n",
    "    gene_slice=gene_slice,\n",
    "    anno_df=anno_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "#Get contribution scores (gradient) for brain GTEX tracks\n",
    "# (~20 minutes on CPU; otherwise runnable only on 40GB GPU cards, e.g. A100)\n",
    "\n",
    "_, _, [pred_grad_wt] = get_prediction_gradient_w_rc(\n",
    "    models,\n",
    "    [sequence_one_hot_wt],\n",
    "    prox_bin_start=0,\n",
    "    prox_bin_end=1,\n",
    "    dist_bin_start=0,\n",
    "    dist_bin_end=1,\n",
    "    track_index=target_index[[17, 18, 19]].tolist(),\n",
    "    track_scale=0.01,\n",
    "    track_transform=3./4.,\n",
    "    clip_soft=384.,\n",
    "    dist_bin_index=gene_slice.tolist(),\n",
    "    use_mean=False,\n",
    "    use_ratio=False,\n",
    "    use_logodds=False,\n",
    "    subtract_avg=True,\n",
    "    fold_index=np.arange(n_folds).tolist(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assume pred_grad_wt is already defined\n",
    "# Replace this line with the actual call to your function that defines pred_grad_wt\n",
    "# _, _, [pred_grad_wt, pred_grad_mut] = get_prediction_gradient_w_rc(...)\n",
    "\n",
    "# Save the pred_grad_wt using pickle\n",
    "with open('pred_grad_wt.pkl', 'wb') as f:\n",
    "    pickle.dump(pred_grad_wt, f)\n",
    "\n",
    "print(\"pred_grad_wt has been saved to 'pred_grad_wt.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199003f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize gradient contribution scores (128 bp window centered on variant)\n",
    "\n",
    "visualize_input_gradient_pair(\n",
    "    pred_grad_wt,\n",
    "    pred_grad_mut,\n",
    "    plot_start=(poses[0] - start) - 64,\n",
    "    plot_end=(poses[0] - start) + 64,\n",
    "    save_figs=False,\n",
    "    fig_name=chrom + '_' + str(poses[0]) + '_prediction_grad_gtex_snp_4_folds_gtex_blood_cov_undo_clip'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Get contribution scores (ISM) for blood GTEX tracks\n",
    "# (not feasible to run on CPU; ~33 minutes on GPU)\n",
    "\n",
    "[pred_ism_wt, pred_ism_mut] = get_ism(\n",
    "    models,\n",
    "    [sequence_one_hot_wt, sequence_one_hot_mut],\n",
    "    ism_start=(poses[0] - start) - 64,\n",
    "    ism_end=(poses[0] - start) + 64,\n",
    "    prox_bin_start=0,\n",
    "    prox_bin_end=1,\n",
    "    dist_bin_start=0,\n",
    "    dist_bin_end=1,\n",
    "    track_index=[9, 10, 11],\n",
    "    track_scale=0.01,\n",
    "    track_transform=3./4.,\n",
    "    clip_soft=384.,\n",
    "    dist_bin_index=gene_slice.tolist(),\n",
    "    use_mean=True,\n",
    "    use_ratio=False,\n",
    "    use_logodds=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ecd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize ISM contribution scores (128 bp window centered on variant)\n",
    "\n",
    "visualize_input_gradient_pair(\n",
    "    pred_ism_wt,\n",
    "    pred_ism_mut,\n",
    "    plot_start=(poses[0] - start) - 64,\n",
    "    plot_end=(poses[0] - start) + 64,\n",
    "    save_figs=False,\n",
    "    fig_name=chrom + '_' + str(poses[0]) + '_prediction_ism_gtex_snp_4_folds_gtex_blood_cov_undo_clip'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Get contribution scores (ISM shuffle) for blood GTEX tracks\n",
    "# (not feasible to run on CPU; ~135 minutes on GPU)\n",
    "\n",
    "[pred_ism_wt, pred_ism_mut] = get_ism_shuffle(\n",
    "    models,\n",
    "    [sequence_one_hot_wt, sequence_one_hot_mut],\n",
    "    ism_start=(poses[0] - start) - 64,\n",
    "    ism_end=(poses[0] - start) + 64,\n",
    "    prox_bin_start=0,\n",
    "    prox_bin_end=1,\n",
    "    dist_bin_start=0,\n",
    "    dist_bin_end=1,\n",
    "    track_index=[9, 10, 11],\n",
    "    track_scale=0.01,\n",
    "    track_transform=3./4.,\n",
    "    clip_soft=384.,\n",
    "    window_size=5,\n",
    "    n_samples=12,\n",
    "    dist_bin_index=gene_slice.tolist(),\n",
    "    use_mean=True,\n",
    "    use_ratio=False,\n",
    "    use_logodds=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize ISM Shuffle contribution scores (128 bp window centered on variant)\n",
    "\n",
    "visualize_input_gradient_pair(\n",
    "    pred_ism_wt,\n",
    "    pred_ism_mut,\n",
    "    plot_start=(poses[0] - start) - 64,\n",
    "    plot_end=(poses[0] - start) + 64,\n",
    "    save_figs=False,\n",
    "    fig_name=chrom + '_' + str(poses[0]) + '_prediction_ism_shuffle_gtex_snp_4_folds_gtex_blood_cov_undo_clip'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load samples with reference- and alternate alleles respectively\n",
    "\n",
    "#These files are protected by dbGaP - email to request access\n",
    "\n",
    "cov_files_wt = pd.read_csv(\"gtex_ref_chr10_116952944_T_C.txt\", sep='\\t', names=['file'])['file'].values.tolist()\n",
    "cov_files_mut = pd.read_csv(\"gtex_alt_chr10_116952944_T_C.txt\", sep='\\t', names=['file'])['file'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738424ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize measured coverage tracks for chr10_116952944_T_C\n",
    "\n",
    "save_figs = False\n",
    "save_suffix = '_chr10_116952944_T_C_meas_32_subjects'\n",
    "\n",
    "center_pos = 116952944\n",
    "\n",
    "chrom = 'chr10'\n",
    "poses = [116952944]\n",
    "alts = ['C']\n",
    "\n",
    "start = center_pos - seq_len // 2\n",
    "end = center_pos + seq_len // 2\n",
    "\n",
    "blacklist_bed = \"/home/drk/common/data/genomes/hg38/blacklist/blacklist_hg38_all.bed\"\n",
    "\n",
    "read_coverage_func_wt, close_coverage_func_wt = get_coverage_reader(cov_files_wt, 16384, 16, blacklist_bed)\n",
    "read_coverage_func_mut, close_coverage_func_mut = get_coverage_reader(cov_files_mut, 16384, 16, blacklist_bed)\n",
    "\n",
    "gtex_targets_wt = read_coverage_func_wt(chrom, start, end, clip_soft=384., clip=768., scale=0.01)\n",
    "gtex_targets_mut = read_coverage_func_mut(chrom, start, end, clip_soft=384., clip=768., scale=0.01)\n",
    "\n",
    "close_coverage_func_wt()\n",
    "close_coverage_func_mut()\n",
    "\n",
    "print(\"gtex_targets_wt.shape = \" + str(gtex_targets_wt.shape))\n",
    "print(\"gtex_targets_mut.shape = \" + str(gtex_targets_mut.shape))\n",
    "\n",
    "plot_window = 131072\n",
    "bin_size = 32\n",
    "pad = 16\n",
    "\n",
    "anno_df = None #splice_df\n",
    "\n",
    "rescale_tracks = True\n",
    "normalize_counts = True\n",
    "\n",
    "#Tracks\n",
    "track_indices = [\n",
    "    np.arange(32).tolist(),\n",
    "]\n",
    "\n",
    "track_names = [\n",
    "    'GTEx Blood (32 subjects)',\n",
    "]\n",
    "\n",
    "track_scales = [\n",
    "    0.01,\n",
    "]\n",
    "\n",
    "track_transforms = [\n",
    "    3./4.,\n",
    "]\n",
    "\n",
    "soft_clips = [\n",
    "    384.,\n",
    "]\n",
    "\n",
    "print(\"-- Counts --\")\n",
    "plot_coverage_track_pair_bins(\n",
    "    gtex_targets_wt[None, None, ...],\n",
    "    gtex_targets_mut[None, None, ...],\n",
    "    chrom,\n",
    "    start,\n",
    "    center_pos,\n",
    "    poses,\n",
    "    track_indices,\n",
    "    track_names,\n",
    "    track_scales,\n",
    "    track_transforms,\n",
    "    soft_clips,\n",
    "    plot_window=plot_window,\n",
    "    normalize_window=4 * plot_window,\n",
    "    bin_size=bin_size,\n",
    "    pad=pad,\n",
    "    rescale_tracks=rescale_tracks,\n",
    "    normalize_counts=normalize_counts,\n",
    "    save_figs=save_figs,\n",
    "    save_suffix=save_suffix,\n",
    "    gene_slice=gene_slice,\n",
    "    anno_df=anno_df,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a9c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
